{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf664784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from difflib import SequenceMatcher\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Sample DataFrame setup\n",
    "data = {\n",
    "    'Ticket': range(1, 21),\n",
    "    'Business Service': [\n",
    "        'Microsoft Outlook', 'Microsoft Windows', 'Laptop', 'Python',\n",
    "        'voice log', 'crm service', 'cwhh vdi', 'vantage agent portal',\n",
    "        'Microsoft Excel', 'MS Excel', 'Excel 365', 'outlook email',\n",
    "        'Outlook client', 'Windows 10', 'Microsoft Windows 11',\n",
    "        'laptop hardware', 'laptop support', 'python development',\n",
    "        'Python scripting', 'CRM system'\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Method 1: LLM-based approach\n",
    "def llm_based_standardization(df, chat_function):\n",
    "    \"\"\"\n",
    "    Use LLM to group similar services and standardize them\n",
    "    \"\"\"\n",
    "    # Get unique services and their counts\n",
    "    service_counts = df['Business Service'].value_counts()\n",
    "    unique_services = service_counts.index.tolist()\n",
    "    \n",
    "    # Create prompt for LLM to group similar services\n",
    "    prompt = f\"\"\"\n",
    "    I have a list of business services that need to be standardized. Please group similar services together and for each group, suggest the most representative name (preferably the one that appears most frequently).\n",
    "\n",
    "    Services with their counts:\n",
    "    {dict(service_counts)}\n",
    "\n",
    "    Please return a JSON object where:\n",
    "    - Keys are the standardized service names\n",
    "    - Values are lists of all variations that should map to that standardized name\n",
    "\n",
    "    Example format:\n",
    "    {{\n",
    "        \"Microsoft Excel\": [\"Microsoft Excel\", \"MS Excel\", \"Excel 365\"],\n",
    "        \"Microsoft Outlook\": [\"Microsoft Outlook\", \"outlook email\", \"Outlook client\"]\n",
    "    }}\n",
    "\n",
    "    Focus on grouping services that refer to the same underlying technology or service.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Call the LLM function\n",
    "        response = chat_function(prompt)\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        # Note: You might need to extract JSON from the response text\n",
    "        standardization_map = json.loads(response)\n",
    "        \n",
    "        # Create a mapping from original to standardized\n",
    "        service_mapping = {}\n",
    "        for standard_name, variations in standardization_map.items():\n",
    "            for variation in variations:\n",
    "                service_mapping[variation] = standard_name\n",
    "        \n",
    "        # Apply mapping to create new column\n",
    "        df['New Services'] = df['Business Service'].map(\n",
    "            lambda x: service_mapping.get(x, x)\n",
    "        )\n",
    "        \n",
    "        return df, service_mapping\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in LLM processing: {e}\")\n",
    "        return df, {}\n",
    "\n",
    "# Method 2: Traditional NLP approach\n",
    "def traditional_nlp_standardization(df, similarity_threshold=80):\n",
    "    \"\"\"\n",
    "    Use fuzzy matching and pattern recognition to standardize services\n",
    "    \"\"\"\n",
    "    # Get service counts\n",
    "    service_counts = df['Business Service'].value_counts()\n",
    "    unique_services = list(service_counts.index)\n",
    "    \n",
    "    # Preprocessing function\n",
    "    def preprocess_service(service):\n",
    "        # Convert to lowercase, remove extra spaces, common prefixes/suffixes\n",
    "        service = service.lower().strip()\n",
    "        service = re.sub(r'\\bmicrosoft\\b|\\bms\\b', 'microsoft', service)\n",
    "        service = re.sub(r'\\b365\\b|\\boffice\\b', '', service).strip()\n",
    "        service = re.sub(r'\\s+', ' ', service)\n",
    "        return service\n",
    "    \n",
    "    # Create groups of similar services\n",
    "    groups = []\n",
    "    used_services = set()\n",
    "    \n",
    "    for service in unique_services:\n",
    "        if service in used_services:\n",
    "            continue\n",
    "            \n",
    "        # Find similar services\n",
    "        similar_services = [service]\n",
    "        used_services.add(service)\n",
    "        \n",
    "        for other_service in unique_services:\n",
    "            if other_service in used_services:\n",
    "                continue\n",
    "                \n",
    "            # Check similarity using multiple methods\n",
    "            similarity_scores = [\n",
    "                fuzz.ratio(preprocess_service(service), preprocess_service(other_service)),\n",
    "                fuzz.partial_ratio(service.lower(), other_service.lower()),\n",
    "                fuzz.token_sort_ratio(service.lower(), other_service.lower()),\n",
    "                fuzz.token_set_ratio(service.lower(), other_service.lower())\n",
    "            ]\n",
    "            \n",
    "            max_similarity = max(similarity_scores)\n",
    "            \n",
    "            # Also check for keyword overlap\n",
    "            service_words = set(preprocess_service(service).split())\n",
    "            other_words = set(preprocess_service(other_service).split())\n",
    "            word_overlap = len(service_words & other_words) / max(len(service_words), len(other_words))\n",
    "            \n",
    "            if max_similarity >= similarity_threshold or word_overlap >= 0.6:\n",
    "                similar_services.append(other_service)\n",
    "                used_services.add(other_service)\n",
    "        \n",
    "        if len(similar_services) > 1:\n",
    "            groups.append(similar_services)\n",
    "    \n",
    "    # For each group, find the service with highest count\n",
    "    service_mapping = {}\n",
    "    for group in groups:\n",
    "        # Get counts for services in this group\n",
    "        group_counts = {service: service_counts[service] for service in group}\n",
    "        # Find the service with maximum count\n",
    "        standard_service = max(group_counts, key=group_counts.get)\n",
    "        \n",
    "        # Map all services in group to the standard one\n",
    "        for service in group:\n",
    "            service_mapping[service] = standard_service\n",
    "    \n",
    "    # Apply mapping\n",
    "    df['New Services'] = df['Business Service'].map(\n",
    "        lambda x: service_mapping.get(x, x)\n",
    "    )\n",
    "    \n",
    "    return df, service_mapping, groups\n",
    "\n",
    "# Method 3: Hybrid approach\n",
    "def hybrid_standardization(df, chat_function, similarity_threshold=75):\n",
    "    \"\"\"\n",
    "    Combine traditional NLP for initial grouping and LLM for validation/refinement\n",
    "    \"\"\"\n",
    "    # Step 1: Use traditional NLP for initial grouping\n",
    "    df_temp, initial_mapping, groups = traditional_nlp_standardization(\n",
    "        df.copy(), similarity_threshold\n",
    "    )\n",
    "    \n",
    "    # Step 2: Use LLM to validate and refine the groups\n",
    "    if groups:\n",
    "        prompt = f\"\"\"\n",
    "        I've used fuzzy matching to group similar business services. Please review these groups and suggest improvements:\n",
    "\n",
    "        Groups found:\n",
    "        {json.dumps(groups, indent=2)}\n",
    "\n",
    "        Service counts:\n",
    "        {dict(df['Business Service'].value_counts())}\n",
    "\n",
    "        Please return a JSON object with refined groupings where:\n",
    "        - Keys are the best representative names for each service category\n",
    "        - Values are lists of all variations that should map to that name\n",
    "        \n",
    "        Validate that the groupings make sense semantically.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = chat_function(prompt)\n",
    "            refined_mapping = json.loads(response)\n",
    "            \n",
    "            # Create final mapping\n",
    "            final_service_mapping = {}\n",
    "            for standard_name, variations in refined_mapping.items():\n",
    "                for variation in variations:\n",
    "                    final_service_mapping[variation] = standard_name\n",
    "            \n",
    "            df['New Services'] = df['Business Service'].map(\n",
    "                lambda x: final_service_mapping.get(x, x)\n",
    "            )\n",
    "            \n",
    "            return df, final_service_mapping\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in LLM refinement: {e}\")\n",
    "            return df_temp, initial_mapping\n",
    "    \n",
    "    return df_temp, initial_mapping\n",
    "\n",
    "# Example usage and comparison\n",
    "def compare_methods(df):\n",
    "    \"\"\"\n",
    "    Compare the effectiveness of different methods\n",
    "    \"\"\"\n",
    "    print(\"Original services:\")\n",
    "    print(df['Business Service'].value_counts())\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Traditional NLP method\n",
    "    df_traditional, mapping_traditional, groups = traditional_nlp_standardization(df.copy())\n",
    "    print(\"Traditional NLP Results:\")\n",
    "    print(\"Groups found:\", groups)\n",
    "    print(\"Standardized services:\")\n",
    "    print(df_traditional['New Services'].value_counts())\n",
    "    print(f\"Reduced from {df['Business Service'].nunique()} to {df_traditional['New Services'].nunique()} unique services\")\n",
    "    \n",
    "    return df_traditional, mapping_traditional\n",
    "\n",
    "# Mock chat function for testing (replace with your actual LLM endpoint)\n",
    "def mock_chat_function(prompt):\n",
    "    \"\"\"\n",
    "    Mock LLM function - replace this with your actual chat function\n",
    "    \"\"\"\n",
    "    # This is a mock response - your actual LLM should analyze the prompt\n",
    "    mock_response = '''\n",
    "    {\n",
    "        \"Microsoft Excel\": [\"Microsoft Excel\", \"MS Excel\", \"Excel 365\"],\n",
    "        \"Microsoft Outlook\": [\"Microsoft Outlook\", \"outlook email\", \"Outlook client\"],\n",
    "        \"Microsoft Windows\": [\"Microsoft Windows\", \"Windows 10\", \"Microsoft Windows 11\"],\n",
    "        \"Laptop\": [\"Laptop\", \"laptop hardware\", \"laptop support\"],\n",
    "        \"Python\": [\"Python\", \"python development\", \"Python scripting\"],\n",
    "        \"CRM Service\": [\"crm service\", \"CRM system\"],\n",
    "        \"Voice Log\": [\"voice log\"],\n",
    "        \"CWHH VDI\": [\"cwhh vdi\"],\n",
    "        \"Vantage Agent Portal\": [\"vantage agent portal\"]\n",
    "    }\n",
    "    '''\n",
    "    return mock_response\n",
    "\n",
    "# Run comparison\n",
    "if __name__ == \"__main__\":\n",
    "    # Test traditional method\n",
    "    df_result, mapping = compare_methods(df)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    print(\"Final DataFrame with standardized services:\")\n",
    "    print(df_result[['Business Service', 'New Services']].head(10))\n",
    "    \n",
    "    # Test LLM method (uncomment when you have actual chat function)\n",
    "    # df_llm, mapping_llm = llm_based_standardization(df.copy(), your_chat_function)\n",
    "    # print(\"LLM Results:\", df_llm['New Services'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6acd27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "def llm_service_standardization(df: pd.DataFrame, chat_function, \n",
    "                              service_column: str = 'Business Service',\n",
    "                              new_column: str = 'New Services') -> Tuple[pd.DataFrame, Dict]:\n",
    "    \"\"\"\n",
    "    Standardize business services using LLM with robust error handling\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the service data\n",
    "        chat_function: Your LLM chat function\n",
    "        service_column: Name of column containing services to standardize\n",
    "        new_column: Name of new column for standardized services\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (updated_dataframe, service_mapping_dict)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get service counts\n",
    "    service_counts = df[service_column].value_counts()\n",
    "    \n",
    "    # Create the prompt\n",
    "    prompt = create_standardization_prompt(service_counts)\n",
    "    \n",
    "    try:\n",
    "        # Call your LLM\n",
    "        print(\"Calling LLM for service standardization...\")\n",
    "        response = chat_function(prompt)\n",
    "        print(f\"LLM Response received: {len(response)} characters\")\n",
    "        \n",
    "        # Parse the response\n",
    "        standardization_map = parse_llm_response(response)\n",
    "        \n",
    "        # Validate the mapping\n",
    "        standardization_map = validate_mapping(standardization_map, service_counts.index.tolist())\n",
    "        \n",
    "        # Apply the mapping\n",
    "        df = apply_service_mapping(df, standardization_map, service_column, new_column)\n",
    "        \n",
    "        # Print results\n",
    "        print_results(df, service_column, new_column, standardization_map)\n",
    "        \n",
    "        return df, standardization_map\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in LLM standardization: {e}\")\n",
    "        # Fallback: copy original column\n",
    "        df[new_column] = df[service_column]\n",
    "        return df, {}\n",
    "\n",
    "def create_standardization_prompt(service_counts) -> str:\n",
    "    \"\"\"Create a detailed prompt for the LLM\"\"\"\n",
    "    \n",
    "    services_text = \"\\n\".join([f\"- {service}: {count} occurrences\" \n",
    "                              for service, count in service_counts.items()])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are helping standardize business service names in a IT ticketing system. \n",
    "\n",
    "TASK: Group similar services together and choose the best representative name for each group.\n",
    "\n",
    "SERVICES AND THEIR FREQUENCIES:\n",
    "{services_text}\n",
    "\n",
    "RULES:\n",
    "1. Group services that refer to the same underlying technology/service\n",
    "2. For each group, choose the name with the HIGHEST frequency as the standard\n",
    "3. If frequencies are equal, choose the most descriptive/official name\n",
    "4. Keep unrelated services separate\n",
    "5. Be conservative - only group if you're confident they're the same service\n",
    "\n",
    "EXAMPLES of what should be grouped:\n",
    "- \"Microsoft Excel\", \"MS Excel\", \"Excel 365\" → all refer to Excel\n",
    "- \"Microsoft Outlook\", \"Outlook email\", \"Outlook client\" → all refer to Outlook\n",
    "- \"Windows 10\", \"Microsoft Windows 11\", \"Microsoft Windows\" → all refer to Windows OS\n",
    "\n",
    "EXAMPLES of what should NOT be grouped:\n",
    "- \"Python\" and \"Java\" → different programming languages\n",
    "- \"Laptop\" and \"Desktop\" → different hardware types\n",
    "- \"CRM\" and \"ERP\" → different software categories\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Return ONLY a valid JSON object with this exact structure:\n",
    "{{\n",
    "    \"Standard Service Name 1\": [\"variation1\", \"variation2\", \"variation3\"],\n",
    "    \"Standard Service Name 2\": [\"variation1\", \"variation2\"],\n",
    "    \"Ungrouped Service\": [\"Ungrouped Service\"]\n",
    "}}\n",
    "\n",
    "IMPORTANT: \n",
    "- Include ALL original services in your response\n",
    "- Each service should appear exactly once\n",
    "- Use the exact service names from the input list\n",
    "- Return only the JSON, no additional text\n",
    "\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def parse_llm_response(response: str) -> Dict:\n",
    "    \"\"\"Parse LLM response and extract JSON mapping\"\"\"\n",
    "    \n",
    "    # Try to find JSON in the response\n",
    "    json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "    \n",
    "    if json_match:\n",
    "        json_str = json_match.group()\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON decode error: {e}\")\n",
    "            print(f\"Problematic JSON: {json_str[:200]}...\")\n",
    "    \n",
    "    # If direct parsing fails, try to clean the response\n",
    "    try:\n",
    "        # Remove markdown code blocks if present\n",
    "        cleaned = re.sub(r'```json\\s*|\\s*```', '', response)\n",
    "        cleaned = re.sub(r'```\\s*|\\s*```', '', cleaned)\n",
    "        \n",
    "        # Find the JSON object\n",
    "        start = cleaned.find('{')\n",
    "        end = cleaned.rfind('}') + 1\n",
    "        \n",
    "        if start != -1 and end > start:\n",
    "            json_str = cleaned[start:end]\n",
    "            return json.loads(json_str)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning response: {e}\")\n",
    "    \n",
    "    raise ValueError(\"Could not parse valid JSON from LLM response\")\n",
    "\n",
    "def validate_mapping(mapping: Dict, original_services: List[str]) -> Dict:\n",
    "    \"\"\"Validate and fix the LLM mapping\"\"\"\n",
    "    \n",
    "    # Flatten all mapped services\n",
    "    mapped_services = set()\n",
    "    for variations in mapping.values():\n",
    "        mapped_services.update(variations)\n",
    "    \n",
    "    # Find missing services\n",
    "    original_set = set(original_services)\n",
    "    missing_services = original_set - mapped_services\n",
    "    \n",
    "    # Add missing services as standalone entries\n",
    "    for service in missing_services:\n",
    "        mapping[service] = [service]\n",
    "        print(f\"Added missing service: {service}\")\n",
    "    \n",
    "    # Remove any services not in original list\n",
    "    cleaned_mapping = {}\n",
    "    for standard_name, variations in mapping.items():\n",
    "        valid_variations = [v for v in variations if v in original_set]\n",
    "        if valid_variations:\n",
    "            cleaned_mapping[standard_name] = valid_variations\n",
    "    \n",
    "    return cleaned_mapping\n",
    "\n",
    "def apply_service_mapping(df: pd.DataFrame, mapping: Dict, \n",
    "                         service_column: str, new_column: str) -> pd.DataFrame:\n",
    "    \"\"\"Apply the standardization mapping to the dataframe\"\"\"\n",
    "    \n",
    "    # Create reverse mapping: original_service -> standard_service\n",
    "    service_map = {}\n",
    "    for standard_name, variations in mapping.items():\n",
    "        for variation in variations:\n",
    "            service_map[variation] = standard_name\n",
    "    \n",
    "    # Apply mapping\n",
    "    df[new_column] = df[service_column].map(service_map)\n",
    "    \n",
    "    # Handle any unmapped services (shouldn't happen with validation)\n",
    "    unmapped_mask = df[new_column].isna()\n",
    "    if unmapped_mask.any():\n",
    "        print(f\"Warning: {unmapped_mask.sum()} services couldn't be mapped\")\n",
    "        df.loc[unmapped_mask, new_column] = df.loc[unmapped_mask, service_column]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def print_results(df: pd.DataFrame, original_col: str, new_col: str, mapping: Dict):\n",
    "    \"\"\"Print standardization results\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STANDARDIZATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    original_unique = df[original_col].nunique()\n",
    "    new_unique = df[new_col].nunique()\n",
    "    reduction = original_unique - new_unique\n",
    "    \n",
    "    print(f\"Original unique services: {original_unique}\")\n",
    "    print(f\"Standardized unique services: {new_unique}\")\n",
    "    print(f\"Reduction: {reduction} services ({reduction/original_unique*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nGROUPINGS MADE:\")\n",
    "    for standard_name, variations in mapping.items():\n",
    "        if len(variations) > 1:\n",
    "            print(f\"\\n'{standard_name}' ← {variations}\")\n",
    "    \n",
    "    print(f\"\\nFINAL SERVICE DISTRIBUTION:\")\n",
    "    print(df[new_col].value_counts().head(10))\n",
    "\n",
    "# USAGE EXAMPLE WITH YOUR CHAT FUNCTION\n",
    "def example_usage():\n",
    "    \"\"\"\n",
    "    Example of how to use with your actual chat function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Ticket': range(1, 21),\n",
    "        'Business Service': [\n",
    "            'Microsoft Outlook', 'Microsoft Windows', 'Laptop', 'Python',\n",
    "            'voice log', 'crm service', 'cwhh vdi', 'vantage agent portal',\n",
    "            'Microsoft Excel', 'MS Excel', 'Excel 365', 'outlook email',\n",
    "            'Outlook client', 'Windows 10', 'Microsoft Windows 11',\n",
    "            'laptop hardware', 'laptop support', 'python development',\n",
    "            'Python scripting', 'CRM system'\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Replace this with your actual chat function\n",
    "    def your_chat_function(prompt):\n",
    "        \"\"\"\n",
    "        Replace this with your actual LLM endpoint\n",
    "        \"\"\"\n",
    "        # Example: return chat(prompt)\n",
    "        # or: return openai.chat.completions.create(...)\n",
    "        # or: return your_llm_api_call(prompt)\n",
    "        \n",
    "        # For now, using a mock response\n",
    "        return '''\n",
    "        {\n",
    "            \"Microsoft Excel\": [\"Microsoft Excel\", \"MS Excel\", \"Excel 365\"],\n",
    "            \"Microsoft Outlook\": [\"Microsoft Outlook\", \"outlook email\", \"Outlook client\"],\n",
    "            \"Microsoft Windows\": [\"Microsoft Windows\", \"Windows 10\", \"Microsoft Windows 11\"],\n",
    "            \"Laptop\": [\"Laptop\", \"laptop hardware\", \"laptop support\"],\n",
    "            \"Python\": [\"Python\", \"python development\", \"Python scripting\"],\n",
    "            \"CRM service\": [\"crm service\", \"CRM system\"],\n",
    "            \"voice log\": [\"voice log\"],\n",
    "            \"cwhh vdi\": [\"cwhh vdi\"],\n",
    "            \"vantage agent portal\": [\"vantage agent portal\"]\n",
    "        }\n",
    "        '''\n",
    "    \n",
    "    # Run the standardization\n",
    "    df_result, mapping = llm_service_standardization(\n",
    "        df=df,\n",
    "        chat_function=your_chat_function,  # Replace with your actual function\n",
    "        service_column='Business Service',\n",
    "        new_column='New Services'\n",
    "    )\n",
    "    \n",
    "    return df_result, mapping\n",
    "\n",
    "# INTEGRATION PATTERNS FOR DIFFERENT LLM PROVIDERS\n",
    "\n",
    "def openai_integration_example():\n",
    "    \"\"\"Example for OpenAI API\"\"\"\n",
    "    import openai\n",
    "    \n",
    "    def chat_with_openai(prompt):\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.1  # Low temperature for consistent results\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "def anthropic_integration_example():\n",
    "    \"\"\"Example for Anthropic Claude API\"\"\"\n",
    "    import anthropic\n",
    "    \n",
    "    client = anthropic.Anthropic(api_key=\"your-api-key\")\n",
    "    \n",
    "    def chat_with_claude(prompt):\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-sonnet-20240229\",\n",
    "            max_tokens=2000,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.content[0].text\n",
    "\n",
    "def custom_endpoint_example():\n",
    "    \"\"\"Example for custom API endpoint\"\"\"\n",
    "    import requests\n",
    "    \n",
    "    def chat_with_custom_api(prompt):\n",
    "        response = requests.post(\n",
    "            \"https://your-api-endpoint.com/chat\",\n",
    "            json={\"prompt\": prompt, \"max_tokens\": 2000},\n",
    "            headers={\"Authorization\": \"Bearer your-token\"}\n",
    "        )\n",
    "        return response.json()[\"response\"]\n",
    "\n",
    "# Run the example\n",
    "if __name__ == \"__main__\":\n",
    "    df_result, mapping = example_usage()\n",
    "    \n",
    "    print(\"\\nSample of final results:\")\n",
    "    print(df_result[['Business Service', 'New Services']].head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
