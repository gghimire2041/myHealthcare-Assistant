{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf664784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from difflib import SequenceMatcher\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Sample DataFrame setup\n",
    "data = {\n",
    "    'Ticket': range(1, 21),\n",
    "    'Business Service': [\n",
    "        'Microsoft Outlook', 'Microsoft Windows', 'Laptop', 'Python',\n",
    "        'voice log', 'crm service', 'cwhh vdi', 'vantage agent portal',\n",
    "        'Microsoft Excel', 'MS Excel', 'Excel 365', 'outlook email',\n",
    "        'Outlook client', 'Windows 10', 'Microsoft Windows 11',\n",
    "        'laptop hardware', 'laptop support', 'python development',\n",
    "        'Python scripting', 'CRM system'\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Method 1: LLM-based approach\n",
    "def llm_based_standardization(df, chat_function):\n",
    "    \"\"\"\n",
    "    Use LLM to group similar services and standardize them\n",
    "    \"\"\"\n",
    "    # Get unique services and their counts\n",
    "    service_counts = df['Business Service'].value_counts()\n",
    "    unique_services = service_counts.index.tolist()\n",
    "    \n",
    "    # Create prompt for LLM to group similar services\n",
    "    prompt = f\"\"\"\n",
    "    I have a list of business services that need to be standardized. Please group similar services together and for each group, suggest the most representative name (preferably the one that appears most frequently).\n",
    "\n",
    "    Services with their counts:\n",
    "    {dict(service_counts)}\n",
    "\n",
    "    Please return a JSON object where:\n",
    "    - Keys are the standardized service names\n",
    "    - Values are lists of all variations that should map to that standardized name\n",
    "\n",
    "    Example format:\n",
    "    {{\n",
    "        \"Microsoft Excel\": [\"Microsoft Excel\", \"MS Excel\", \"Excel 365\"],\n",
    "        \"Microsoft Outlook\": [\"Microsoft Outlook\", \"outlook email\", \"Outlook client\"]\n",
    "    }}\n",
    "\n",
    "    Focus on grouping services that refer to the same underlying technology or service.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Call the LLM function\n",
    "        response = chat_function(prompt)\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        # Note: You might need to extract JSON from the response text\n",
    "        standardization_map = json.loads(response)\n",
    "        \n",
    "        # Create a mapping from original to standardized\n",
    "        service_mapping = {}\n",
    "        for standard_name, variations in standardization_map.items():\n",
    "            for variation in variations:\n",
    "                service_mapping[variation] = standard_name\n",
    "        \n",
    "        # Apply mapping to create new column\n",
    "        df['New Services'] = df['Business Service'].map(\n",
    "            lambda x: service_mapping.get(x, x)\n",
    "        )\n",
    "        \n",
    "        return df, service_mapping\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in LLM processing: {e}\")\n",
    "        return df, {}\n",
    "\n",
    "# Method 2: Traditional NLP approach\n",
    "def traditional_nlp_standardization(df, similarity_threshold=80):\n",
    "    \"\"\"\n",
    "    Use fuzzy matching and pattern recognition to standardize services\n",
    "    \"\"\"\n",
    "    # Get service counts\n",
    "    service_counts = df['Business Service'].value_counts()\n",
    "    unique_services = list(service_counts.index)\n",
    "    \n",
    "    # Preprocessing function\n",
    "    def preprocess_service(service):\n",
    "        # Convert to lowercase, remove extra spaces, common prefixes/suffixes\n",
    "        service = service.lower().strip()\n",
    "        service = re.sub(r'\\bmicrosoft\\b|\\bms\\b', 'microsoft', service)\n",
    "        service = re.sub(r'\\b365\\b|\\boffice\\b', '', service).strip()\n",
    "        service = re.sub(r'\\s+', ' ', service)\n",
    "        return service\n",
    "    \n",
    "    # Create groups of similar services\n",
    "    groups = []\n",
    "    used_services = set()\n",
    "    \n",
    "    for service in unique_services:\n",
    "        if service in used_services:\n",
    "            continue\n",
    "            \n",
    "        # Find similar services\n",
    "        similar_services = [service]\n",
    "        used_services.add(service)\n",
    "        \n",
    "        for other_service in unique_services:\n",
    "            if other_service in used_services:\n",
    "                continue\n",
    "                \n",
    "            # Check similarity using multiple methods\n",
    "            similarity_scores = [\n",
    "                fuzz.ratio(preprocess_service(service), preprocess_service(other_service)),\n",
    "                fuzz.partial_ratio(service.lower(), other_service.lower()),\n",
    "                fuzz.token_sort_ratio(service.lower(), other_service.lower()),\n",
    "                fuzz.token_set_ratio(service.lower(), other_service.lower())\n",
    "            ]\n",
    "            \n",
    "            max_similarity = max(similarity_scores)\n",
    "            \n",
    "            # Also check for keyword overlap\n",
    "            service_words = set(preprocess_service(service).split())\n",
    "            other_words = set(preprocess_service(other_service).split())\n",
    "            word_overlap = len(service_words & other_words) / max(len(service_words), len(other_words))\n",
    "            \n",
    "            if max_similarity >= similarity_threshold or word_overlap >= 0.6:\n",
    "                similar_services.append(other_service)\n",
    "                used_services.add(other_service)\n",
    "        \n",
    "        if len(similar_services) > 1:\n",
    "            groups.append(similar_services)\n",
    "    \n",
    "    # For each group, find the service with highest count\n",
    "    service_mapping = {}\n",
    "    for group in groups:\n",
    "        # Get counts for services in this group\n",
    "        group_counts = {service: service_counts[service] for service in group}\n",
    "        # Find the service with maximum count\n",
    "        standard_service = max(group_counts, key=group_counts.get)\n",
    "        \n",
    "        # Map all services in group to the standard one\n",
    "        for service in group:\n",
    "            service_mapping[service] = standard_service\n",
    "    \n",
    "    # Apply mapping\n",
    "    df['New Services'] = df['Business Service'].map(\n",
    "        lambda x: service_mapping.get(x, x)\n",
    "    )\n",
    "    \n",
    "    return df, service_mapping, groups\n",
    "\n",
    "# Method 3: Hybrid approach\n",
    "def hybrid_standardization(df, chat_function, similarity_threshold=75):\n",
    "    \"\"\"\n",
    "    Combine traditional NLP for initial grouping and LLM for validation/refinement\n",
    "    \"\"\"\n",
    "    # Step 1: Use traditional NLP for initial grouping\n",
    "    df_temp, initial_mapping, groups = traditional_nlp_standardization(\n",
    "        df.copy(), similarity_threshold\n",
    "    )\n",
    "    \n",
    "    # Step 2: Use LLM to validate and refine the groups\n",
    "    if groups:\n",
    "        prompt = f\"\"\"\n",
    "        I've used fuzzy matching to group similar business services. Please review these groups and suggest improvements:\n",
    "\n",
    "        Groups found:\n",
    "        {json.dumps(groups, indent=2)}\n",
    "\n",
    "        Service counts:\n",
    "        {dict(df['Business Service'].value_counts())}\n",
    "\n",
    "        Please return a JSON object with refined groupings where:\n",
    "        - Keys are the best representative names for each service category\n",
    "        - Values are lists of all variations that should map to that name\n",
    "        \n",
    "        Validate that the groupings make sense semantically.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = chat_function(prompt)\n",
    "            refined_mapping = json.loads(response)\n",
    "            \n",
    "            # Create final mapping\n",
    "            final_service_mapping = {}\n",
    "            for standard_name, variations in refined_mapping.items():\n",
    "                for variation in variations:\n",
    "                    final_service_mapping[variation] = standard_name\n",
    "            \n",
    "            df['New Services'] = df['Business Service'].map(\n",
    "                lambda x: final_service_mapping.get(x, x)\n",
    "            )\n",
    "            \n",
    "            return df, final_service_mapping\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in LLM refinement: {e}\")\n",
    "            return df_temp, initial_mapping\n",
    "    \n",
    "    return df_temp, initial_mapping\n",
    "\n",
    "# Example usage and comparison\n",
    "def compare_methods(df):\n",
    "    \"\"\"\n",
    "    Compare the effectiveness of different methods\n",
    "    \"\"\"\n",
    "    print(\"Original services:\")\n",
    "    print(df['Business Service'].value_counts())\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Traditional NLP method\n",
    "    df_traditional, mapping_traditional, groups = traditional_nlp_standardization(df.copy())\n",
    "    print(\"Traditional NLP Results:\")\n",
    "    print(\"Groups found:\", groups)\n",
    "    print(\"Standardized services:\")\n",
    "    print(df_traditional['New Services'].value_counts())\n",
    "    print(f\"Reduced from {df['Business Service'].nunique()} to {df_traditional['New Services'].nunique()} unique services\")\n",
    "    \n",
    "    return df_traditional, mapping_traditional\n",
    "\n",
    "# Mock chat function for testing (replace with your actual LLM endpoint)\n",
    "def mock_chat_function(prompt):\n",
    "    \"\"\"\n",
    "    Mock LLM function - replace this with your actual chat function\n",
    "    \"\"\"\n",
    "    # This is a mock response - your actual LLM should analyze the prompt\n",
    "    mock_response = '''\n",
    "    {\n",
    "        \"Microsoft Excel\": [\"Microsoft Excel\", \"MS Excel\", \"Excel 365\"],\n",
    "        \"Microsoft Outlook\": [\"Microsoft Outlook\", \"outlook email\", \"Outlook client\"],\n",
    "        \"Microsoft Windows\": [\"Microsoft Windows\", \"Windows 10\", \"Microsoft Windows 11\"],\n",
    "        \"Laptop\": [\"Laptop\", \"laptop hardware\", \"laptop support\"],\n",
    "        \"Python\": [\"Python\", \"python development\", \"Python scripting\"],\n",
    "        \"CRM Service\": [\"crm service\", \"CRM system\"],\n",
    "        \"Voice Log\": [\"voice log\"],\n",
    "        \"CWHH VDI\": [\"cwhh vdi\"],\n",
    "        \"Vantage Agent Portal\": [\"vantage agent portal\"]\n",
    "    }\n",
    "    '''\n",
    "    return mock_response\n",
    "\n",
    "# Run comparison\n",
    "if __name__ == \"__main__\":\n",
    "    # Test traditional method\n",
    "    df_result, mapping = compare_methods(df)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    print(\"Final DataFrame with standardized services:\")\n",
    "    print(df_result[['Business Service', 'New Services']].head(10))\n",
    "    \n",
    "    # Test LLM method (uncomment when you have actual chat function)\n",
    "    # df_llm, mapping_llm = llm_based_standardization(df.copy(), your_chat_function)\n",
    "    # print(\"LLM Results:\", df_llm['New Services'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
